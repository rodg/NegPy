# The Pipeline

Here is what actually happens to your image. We apply these steps in order, passing the buffer from one stage to the next.

## 1. Geometry (Straighten & Crop)
**Code**: `src.features.geometry`

*   **Rotation**: We spin the image array (90Â° steps) and fine-tune with affine transformations. We use bilinear interpolation so it stays sharp.
*   **Autocrop**: I try to detect where the film ends and the scanner bed begins by looking for the density jump. It's not perfect (light leaks or weird scanning holders can fool it), so there's a manual override.

**Note:** Cropping happens early because the normalization step needs to know what is "image" and what is "border" to calculate the black/white points correctly.

---

## 2. Scan Normalization
**Code**: `src.features.exposure.normalization`

*   **Physical Model**: We treat the file not as a photo, but as a **radiometric measurement**. The pixel values represent how much light passed through the negative.
*   **Inversion**: Film density is logarithmic ($D \propto \log E$), but scanners and camera sensors are linear. So we invert it to get back to the log space:
    $$E_{log} = \log_{10}(I_{scan})$$
    *   $I_{scan}$: Raw linear input from scanner/camera using 16-bit precision.
*   **Bounds**: We find the floor (film base + fog) and the ceiling (densest highlight) We set those at 0.5th percentile and 99.5th percentile.
*   **Stretch**: We normalize these bounds to $[0, 1]$. This effectively subtracts the orange mask and gives us a clean signal to work with.

---

## 3. The Print (Exposure)
**Code**: `src.features.exposure`

*   **Virtual Darkroom**: This step simulates shining light through the negative onto paper.
*   **Color Timing**: We apply subtractive filtration (CMY) to the digital negative. This is exactly like using a dichroic head on an enlarger to remove color casts.
*   **The H&D Curve**: Paper doesn't respond linearly. We model its response using a **Logistic Sigmoid**:
    $$D_{print} = \frac{D_{max}}{1 + e^{-k \cdot (x - x_0)}}$$
    *   $D_{max}$: Deepest black the paper can do.
    *   $k$: Contrast grade.
    *   $x_0$: Exposure time.
    *   $x$: Input logarithmic exposure.
*   **Toe & Shoulder**: We tweak the curve at the ends.
    *   **Toe**: Controls how fast shadows go to pure black.
    *   **Shoulder**: Controls how highlights roll off.
*   **Output**: Finally, we convert that print density back to light (Transmittance) for your screen:
    $$I_{out} = (10^{-D_{print}})^{1/\gamma}$$
    *   $I_{out}$: Final display intensity.
    *   $\gamma$: Display gamma correction (2.2).

The defaults should be somewhat neutral, but you can (and should) use the sliders to match the curve shape (your "print") to your liking.

---

## 4. Retouching
**Code**: `src.features.retouch`

*   **Dust & Scratches**: We look for sharp spikes in local texture. If a pixel is way different from its neighbors (based on standard deviation), it's probably dust. We then replace it with median of it's neighbors.
    $$|I - \text{median}(I)| > T \cdot f(\sigma)$$
    *   $I$: Pixel intensity.
    *   $T$: Sensitivity threshold.
    *   $f(\sigma)$: Local noise estimate.
*   **Grain Injection**: When you heal a spot, simple blurring looks fake ("plastic"). So we inject synthetic grain back into the healed area, scaled by the brightness (since grain is most visible in midtones).
*   **Dodge & Burn**: Standard darkroom tools. We multiply the pixel intensity to simulate giving it more or less light.
    $$I_{out} = I_{in} \cdot 2^{(\text{strength} \cdot \text{mask})}$$

---

## 5. Lab Scanner Mode
**Code**: `src.features.lab`

This mimics what lab scanners like Frontier or Noritsu do automatically.

*   **Color Separation**: We use a mixing matrix to push colors apart. It mixes between a neutral identity matrix and a "calibration" matrix based on how much pop you want.
    $$M = \text{normalize}((1 - \beta)I + \beta C)$$
    *   $I$: Identity matrix (neutral).
    *   $C$: Calibration matrix (vibrant).
    *   $\beta$: Separation strength.
        
    We use hardcoded calibration matrix for now that should be good for most cases but later I plan to add option to set your own presets for different filmstocks/looks.

*   **CLAHE**: Adaptive histogram equalization. It boosts local contrast in the luminance channel. 
    $$L_{final} = (1 - \alpha) \cdot L + \alpha \cdot \text{CLAHE}(L)$$
    *   $L$: Luminance channel.
    *   $\alpha$: Blending strength.

*   **Sharpening**: We sharpen just the Lightness channel ($L$) in LAB space using Unsharp Masking (USM). We apply a threshold to avoid amplifying noise.
    $$L_{diff} = L - \text{GaussianBlur}(L, \sigma)$$
    $$L_{final} = L + L_{diff} \cdot \text{amount} \cdot 2.5 \quad \text{if } |L_{diff}| > 2.0$$
    *   $\sigma$: Blur radius (scale factor).
    *   $2.5$: Hardcoded USM boosting factor.
    *   $2.0$: Noise threshold.

---

## 6. Toning & Paper Simulation
**Code**: `src.features.toning`

*   **Paper Tint**: We multiply the image by a base color (e.g., warm cream for fiber paper) and tweak the D-max (density boost).
    $$I_{tinted} = (I_{in} \cdot C_{base})^{\gamma_{boost}}$$
    *   $I_{in}$: Input image.
    *   $C_{base}$: Paper tint RGB color.
    *   $\gamma_{boost}$: D-max density boost.

*   **Chemical Toning**: We simulate toning by blending the original pixel with a tinted version based on luminance ($Y$) masks.
    *   **Selenium**: Targets the shadows (inverse squared luminance).
        $$m_{sel} = S_{sel} \cdot (1 - Y)^2$$
        $$I' = I_{tinted} \cdot (1 - m_{sel}) + (I_{tinted} \cdot C_{selenium}) \cdot m_{sel}$$
        *   $Y$: Pixel Luminance.
        *   $S_{sel}$: Selenium strength.
        *   $C_{selenium}$: Selenium target color (purple/reddish).
    *   **Sepia**: Targets the midtones using a Gaussian bell curve centered at $0.6$ luminance.
        $$m_{sep} = S_{sep} \cdot \exp\left(-\frac{(Y - 0.6)^2}{0.08}\right)$$
        $$I_{out} = I' \cdot (1 - m_{sep}) + (I' \cdot C_{sepia}) \cdot m_{sep}$$
        *   $S_{sep}$: Sepia strength.
        *   $C_{sepia}$: Sepia target color (brown/gold).